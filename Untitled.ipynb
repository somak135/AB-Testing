{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bb72d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import Markdown, display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss\n",
    "#from scipy.stats import norm, t\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import decimal\n",
    "decimal.getcontext().prec = 4\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "import io\n",
    "from scipy.special import btdtri\n",
    "from tabulate import tabulate\n",
    "\n",
    "def printmd(string, color='red'):\n",
    "    colorstr = \"<span style='color:{}'>{}</span>\".format(color, string)\n",
    "    display(Markdown(colorstr))\n",
    "\n",
    "\n",
    "def upload_file():\n",
    "    printmd('**Upload the .csv data file with control/treatment in first column and binary observations in second column:**')\n",
    "    uploader = widgets.FileUpload(accept = '.csv', multiple = False)\n",
    "    display(uploader)\n",
    "    return uploader   \n",
    "    \n",
    "    \n",
    "def read_file(uploader):\n",
    "    input_file = list(uploader.value.values())[0]\n",
    "    content = input_file['content']\n",
    "    content = io.StringIO(content.decode('utf-8'))\n",
    "    df = pd.read_csv(content)\n",
    "    return df\n",
    "\n",
    "def do_classical_test(df, level_of_sig):\n",
    "    str1 = df.columns[0]  ## column name of variations\n",
    "    str2 = df.columns[1]  ## column name of observations\n",
    "    \n",
    "    variation1_name = df[str1].unique()[0] ## name of variation 1\n",
    "    variation2_name = df[str1].unique()[1] ## name of variation 2\n",
    "    \n",
    "    dataset1 = df[df[str1] == variation1_name]\n",
    "    dataset2 = df[df[str1] == variation2_name]\n",
    "    \n",
    "    ci_dataset1 = np.sqrt(dataset1[str2].mean()*(1 - dataset1[str2].mean())/len(dataset1[str2]))*ss.norm.ppf(1-level_of_sig/2)\n",
    "    ci_dataset2 = np.sqrt(dataset1[str2].mean()*(1 - dataset1[str2].mean())/len(dataset2[str2]))*ss.norm.ppf(1-level_of_sig/2 )\n",
    "    \n",
    "    p1 = plt.bar(0, dataset1[str2].mean(), color = 'red', edgecolor = 'black', yerr = ci_dataset1, capsize = 15, label = variation1_name, width = 0.2)\n",
    "    p2 = plt.bar(0.4, dataset2[str2].mean(), color = 'green', edgecolor = 'black', yerr = ci_dataset2, capsize = 15, label = variation2_name, width = 0.2)\n",
    "    \n",
    "    plt.legend(handles=[p1, p2], bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.xticks([0, 0.4], [variation1_name, variation2_name])\n",
    "    plt.show()\n",
    "    \n",
    "    t_stat, p_val = ss.ttest_ind(dataset1[str2], dataset2[str2])\n",
    "    \n",
    "    if t_stat<=0 and p_val <= level_of_sig:\n",
    "        printmd(f'**The variation \\'{variation2_name}\\' has significantly higher conversion rate compared to the the \\'{variation1_name}\\'. The p value of the test is {p_val:.5f}.**', color = 'green')\n",
    "        \n",
    "    if t_stat>=0 and p_val <= level_of_sig:\n",
    "        printmd(f'**The variation \\'{variation1_name}\\' has significantly higher conversion rate compared to the \\'{variation2_name}\\'. The p value of the test is {p_val:.5f}.**', color = 'red')\n",
    "        \n",
    "    if p_val > level_of_sig:\n",
    "        printmd(f'**The test is inconclusive. P-value is {p_val: .5f}.**')\n",
    "    #return t_stat, p_val\n",
    "    \n",
    "\n",
    "def calculate_expected_loss(control_simulation, treatment_simulation, treatment_won, min_difference_delta=0):\n",
    "    control_simulation = np.array(control_simulation)\n",
    "    treatment_simulation = np.array(treatment_simulation)\n",
    "    \n",
    "    loss_control = (treatment_simulation - min_difference_delta) - control_simulation\n",
    "    loss_treatment = (control_simulation - min_difference_delta) - treatment_simulation\n",
    "    \n",
    "    all_loss_control = treatment_won * loss_control\n",
    "    all_loss_treatment = (1 - treatment_won) * loss_treatment\n",
    "    \n",
    "    return np.mean(all_loss_control), np.mean(all_loss_treatment)\n",
    "\n",
    "\n",
    "    \n",
    "def do_bayesian_test2(df, eps, prob_beat):\n",
    "    str1 = df.columns[0]\n",
    "    str2 = df.columns[1]\n",
    "    \n",
    "    variation1_name = df[str1].unique()[0]\n",
    "    variation2_name = df[str1].unique()[1]\n",
    "    \n",
    "    if len(df[df[str1] == variation1_name]) < len(df[df[str1] == variation2_name]):\n",
    "        variation1_name = df[str1].unique()[1]\n",
    "        variation2_name = df[str1].unique()[0]\n",
    "        \n",
    "    dataset1 = df[df[str1] == variation1_name]\n",
    "    dataset2 = df[df[str1] == variation2_name]\n",
    "    \n",
    "    variation1_data = np.array(dataset1[str2])\n",
    "    variation2_data = np.array(dataset2[str2])\n",
    "    \n",
    "    variation1_expected_cr = variation1_data.mean() ##to be reported\n",
    "    variation2_expected_cr = variation2_data.mean() ##to be reported\n",
    "    \n",
    "    variation1_conversions = sum(variation1_data)\n",
    "    variation2_conversions = sum(variation2_data)\n",
    "    variation1_sample_size = len(variation1_data)\n",
    "    variation2_sample_size = len(variation2_data)\n",
    "    \n",
    "    variation1_cr_samples = np.random.beta(1+variation1_conversions, 1+variation1_sample_size-variation1_conversions, size=700000)\n",
    "    variation2_cr_samples = np.random.beta(1+variation2_conversions, 1+variation2_sample_size-variation2_conversions, size=700000)\n",
    "    variation1_prob_beat = (variation1_cr_samples >= variation2_cr_samples).astype(int).mean() ## to be reported\n",
    "    variation2_prob_beat = 1 - variation1_prob_beat ##to be reported\n",
    "    variation1_exp_lift = ((variation1_cr_samples - variation2_cr_samples)/variation2_cr_samples).mean() ##to be reported\n",
    "    variation2_exp_lift = ((variation2_cr_samples - variation1_cr_samples)/variation1_cr_samples).mean() ##to be reported\n",
    "    \n",
    "    report_table = tabulate([['Variation name', 'Expected conversion rate', 'Improvement over other', 'Probability to beat other'],\n",
    "                   [f'{variation1_name}', f'{variation1_expected_cr*100:.3f}%', f'{variation1_exp_lift*100:.3f}%', f'{variation1_prob_beat*100:.3f}%'],\n",
    "                   [f'{variation2_name}', f'{variation2_expected_cr*100:.3f}%', f'{variation2_exp_lift*100:.3f}%', f'{variation2_prob_beat*100:.3f}%']])\n",
    "    \n",
    "    variation2_won = (variation2_cr_samples >= variation1_cr_samples).astype(int)\n",
    "    variation1_exp_loss, variation2_exp_loss = calculate_expected_loss(variation1_cr_samples, variation2_cr_samples, variation2_won)\n",
    "    if variation1_exp_loss<=eps and variation1_prob_beat>=prob_beat:\n",
    "        result = f'{variation1_name} is the winner. Expect a relative improvement of {variation1_exp_lift*100}% over {variation2_name}.'\n",
    "    elif variation2_exp_loss<=eps and variation2_prob_beat>=prob_beat:\n",
    "        result = f'{variation2_name} is the winner. Expect a relative improvement of {variation2_exp_lift*100}% over {variation1_name}.'\n",
    "    else:\n",
    "        result = f'There is not enough confidence in declaring a winner.'\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcab113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "style = {'description_width': 'initial'}\n",
    "def do_test(df, level_of_sig, epsilon, string):\n",
    "    if string == 'Classical':\n",
    "        do_classical_test(df, level_of_sig)\n",
    "        \n",
    "    if string == 'Bayesian':\n",
    "        do_bayesian_test2(df, epsilon)\n",
    "    \n",
    "method_choice = widgets.Select(\n",
    "                options = ['Classical', 'Bayesian'],\n",
    "                value = 'Classical',\n",
    "                description = f'<b>Method</b>',\n",
    "                style = style\n",
    ")\n",
    "\n",
    "level_of_sig = widgets.BoundedFloatText(\n",
    "                value = 0.05,\n",
    "                min = 0.01,\n",
    "                max = 0.1,\n",
    "                #step = 0.01,\n",
    "                description = f'<b>Level of Significance</b>',\n",
    "                readout_format = '.4f',\n",
    "                style = style\n",
    ")\n",
    "\n",
    "epsilon = widgets.BoundedFloatText(\n",
    "        value = 0.001,\n",
    "        min = 0.0000001,\n",
    "        max = 0.1,\n",
    "        #step = eps_min,\n",
    "        description = f'<b>Expected Loss Threshold</b>',\n",
    "        #readout = False,\n",
    "        style = style\n",
    ")\n",
    "#eps_label = widgets.Label()\n",
    "#eps_box = widgets.HBox([epsilon, eps_label])\n",
    "#mylink = widgets.jslink((epsilon, 'value'), (eps_label, 'value'))\n",
    "\n",
    "def threshold_display(arr):\n",
    "    if arr == 'Classical':\n",
    "        printmd('**Enter Level of Significance for Classical calculation:**')\n",
    "        display(level_of_sig)\n",
    "            \n",
    "    if arr == 'Bayesian':\n",
    "        printmd('**Enter expected loss threshold:**')\n",
    "        display(epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94823286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style='color:red'>**Upload the .csv data file with control/treatment in first column and binary observations in second column:**</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "838519922bbd430c9c75d16bc501b5c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, accept='.csv', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "up = upload_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bcf9824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style='color:red'>**Choose preferred method for the test.**</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9898b260b64b7eb336296084cc21b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Select(description='<b>Method</b>', options=('Classical', 'Bayesian'), style=DescriptionStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = read_file(up)\n",
    "printmd('**Choose preferred method for the test.**'); display(method_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cab07c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style='color:red'>**Enter expected loss threshold:**</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "990c2b883b4d4bcabdf7e19130867b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BoundedFloatText(value=0.001, description='<b>Expected Loss Threshold</b>', max=0.1, min=1e-07, style=Descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "threshold_display(method_choice.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b084c3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------  ------------------------  ----------------------  -------------------------\n",
      "Variation name  Expected conversion rate  Improvement over other  Probability to beat other\n",
      "control         20.153%                   4.035%                  88.114%\n",
      "treatment       19.380%                   -3.773%                 11.886%\n",
      "--------------  ------------------------  ----------------------  -------------------------\n",
      "There is not enough confidence in declaring a winner.\n"
     ]
    }
   ],
   "source": [
    "do_test(df, level_of_sig.value, epsilon.value, method_choice.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec0b70c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
