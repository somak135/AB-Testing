{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cd469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_delta_simulations():\n",
    "    _, ax = plt.subplots()\n",
    "\n",
    "    percentage_mappings = {2: '5', 5: '15', 9:'30'}\n",
    "\n",
    "    for mte in [2, 5, 9]:\n",
    "        simulations = pd.read_csv(f'experiment_simulations_{32 + mte}.csv')\n",
    "\n",
    "        simulations = simulations[simulations['winner'] != 'inconclusive']\n",
    "        \n",
    "        simulations = simulations[simulations['sample'] >= 200]\n",
    "\n",
    "        grouped = simulations[['simulation', 'sample']].groupby('simulation', as_index=False).min()\n",
    "\n",
    "        results = simulations.merge(grouped, on=['simulation', 'sample'])\n",
    "\n",
    "        hist = results[['simulation', 'sample']].groupby('sample', as_index=False).count()\n",
    "\n",
    "        records = json.loads(hist.set_index('sample').to_json(orient='index'))\n",
    "\n",
    "        conclusive_simulations = 0\n",
    "        print_counter = 0\n",
    "        plotting_conclusions = []\n",
    "        x = list(range(1, 10001))\n",
    "\n",
    "        for i in x:\n",
    "            if str(i) in records:\n",
    "                conclusive_simulations += records[str(i)]['simulation']\n",
    "\n",
    "            if (conclusive_simulations >= 80) and (print_counter < 1):\n",
    "                print(f'For minimum detectable effect of {percentage_mappings[mte]}%, {80}% of simulations needed {i} samples to be conclusive')\n",
    "                print_counter += 1\n",
    "\n",
    "            plotting_conclusions.append(conclusive_simulations)\n",
    "\n",
    "        ax.plot(x, plotting_conclusions, label=f'{percentage_mappings[mte]}%')\n",
    "\n",
    "    ax.plot(list(range(1,10001)), np.full((10000,), 80), label='80% threshold', linestyle='dashed')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Sample Size')\n",
    "    ax.set_ylabel('Proportion of Conclusive Simulations')\n",
    "    ax.set_title('Conclusive Simulations for varying δ')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_epsilon_simulations():\n",
    "    _, ax = plt.subplots()\n",
    "\n",
    "    sim_names = {'low': 'low_eps',\n",
    "                 'medium': '37',\n",
    "                 'high': 'high_eps'}\n",
    "\n",
    "    epsilons = {'low': 0.0005,\n",
    "                 'medium': 0.0015,\n",
    "                 'high': 0.003}\n",
    "\n",
    "    for eps in ['low', 'medium', 'high']:\n",
    "        simulations = pd.read_csv(f'experiment_simulations_{sim_names[eps]}.csv')\n",
    "\n",
    "        simulations = simulations[simulations['winner'] != 'inconclusive']\n",
    "        \n",
    "        simulations = simulations[simulations['sample'] >= 200]\n",
    "\n",
    "        grouped = simulations[['simulation', 'sample']].groupby('simulation', as_index=False).min()\n",
    "\n",
    "        results = simulations.merge(grouped, on=['simulation', 'sample'])\n",
    "\n",
    "        hist = results[['simulation', 'sample']].groupby('sample', as_index=False).count()\n",
    "\n",
    "        records = json.loads(hist.set_index('sample').to_json(orient='index'))\n",
    "\n",
    "        conclusive_simulations = 0\n",
    "        print_counter = 0\n",
    "        plotting_conclusions = []\n",
    "        x = list(range(1, 10001))\n",
    "\n",
    "        for i in x:\n",
    "            if str(i) in records:\n",
    "                conclusive_simulations += records[str(i)]['simulation']\n",
    "\n",
    "            if (conclusive_simulations >= 80) and (print_counter < 1):\n",
    "                print(f'For minimum detectable effect of {epsilons[eps]}%, {80}% of simulations needed {i} samples to be conclusive')\n",
    "                print_counter += 1\n",
    "\n",
    "            plotting_conclusions.append(conclusive_simulations)\n",
    "\n",
    "\n",
    "        ax.plot(x, plotting_conclusions, label=f'{epsilons[eps]}')\n",
    "\n",
    "    ax.plot(list(range(1,10001)), np.full((10000,), 80), label='80% threshold', linestyle='dashed')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Sample Size')\n",
    "    ax.set_ylabel('Proportion of Conclusive Simulations')\n",
    "    ax.set_title('Conclusive Simulations for varying ϵ')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_lambda_simulations():\n",
    "    _, ax = plt.subplots()\n",
    "\n",
    "    lambda_names = {'low': 'low_lambda',\n",
    "                    'medium': '37',\n",
    "                    'high': 'high_lambda'}\n",
    "\n",
    "    lambdas = {'low': 5,\n",
    "               'medium': 32,\n",
    "               'high': 60}\n",
    "\n",
    "    for cr in lambda_names:\n",
    "\n",
    "        simulations = pd.read_csv(f'experiment_simulations_{lambda_names[cr]}.csv')\n",
    "\n",
    "        simulations = simulations[simulations['winner'] != 'inconclusive']\n",
    "        \n",
    "        simulations = simulations[simulations['sample'] >= 200]\n",
    "\n",
    "        grouped = simulations[['simulation', 'sample']].groupby('simulation', as_index=False).min()\n",
    "\n",
    "        results = simulations.merge(grouped, on=['simulation', 'sample'])\n",
    "\n",
    "        hist = results[['simulation', 'sample']].groupby('sample', as_index=False).count()\n",
    "\n",
    "        records = json.loads(hist.set_index('sample').to_json(orient='index'))\n",
    "\n",
    "        conclusive_simulations = 0\n",
    "        print_counter = 0\n",
    "        plotting_conclusions = []\n",
    "        x = list(range(1, 10001))\n",
    "\n",
    "        for i in x:\n",
    "            if str(i) in records:\n",
    "                conclusive_simulations += records[str(i)]['simulation']\n",
    "\n",
    "            if (conclusive_simulations >= 80) and (print_counter < 1):\n",
    "                print(f'For minimum detectable effect of {lambdas[cr]}%, {80}% of simulations needed {i} samples to be conclusive')\n",
    "                print_counter += 1\n",
    "\n",
    "            plotting_conclusions.append(conclusive_simulations)\n",
    "\n",
    "\n",
    "        ax.plot(x, plotting_conclusions, label=f'{lambdas[cr]}%')\n",
    "    \n",
    "    ax.plot(list(range(1,10001)), np.full((10000,), 80), label='80% threshold', linestyle='dashed')\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Sample Size')\n",
    "    ax.set_ylabel('Proportion of Conclusive Simulations')\n",
    "    ax.set_title('Conclusive Simulations for varying λ')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    plot_delta_simulations()\n",
    "\n",
    "    plot_epsilon_simulations()\n",
    "\n",
    "    plot_lambda_simulations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c110963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_peeking_example():\n",
    "    simulations = pd.read_csv('experiment_simulations_same_cr.csv')\n",
    "    simulations['sample'] = simulations['sample'] + 1\n",
    "\n",
    "    for i in set(simulations['simulation'].values):\n",
    "        if i != 3:\n",
    "            continue\n",
    "\n",
    "        filtered_simulation = simulations[simulations['simulation'] == i]\n",
    "\n",
    "        _, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "        \n",
    "        ax1.plot(filtered_simulation['sample'], filtered_simulation['treatment_expected_loss'], label='treatment')\n",
    "        ax1.plot(filtered_simulation['sample'], filtered_simulation['control_expected_loss'], label='control')\n",
    "        ax1.plot(filtered_simulation['sample'], np.full((10000,), 0.003), label='threshold', linestyle='dashed')\n",
    "        ax1.set_xlabel('Sample Size')\n",
    "        ax1.set_ylabel('Expected Loss')\n",
    "        ax1.set_title('Expected Loss Simulation')\n",
    "        ax1.legend()\n",
    "        \n",
    "        \n",
    "        ax2.plot(filtered_simulation['sample'], filtered_simulation['treatment_cr'], label='treatment')\n",
    "        ax2.plot(filtered_simulation['sample'], filtered_simulation['control_cr'], label='control')\n",
    "        ax2.set_xlabel('Sample Size')\n",
    "        ax2.set_ylabel('Conversion Rates')\n",
    "        ax2.set_title('Conversion Rates Simulation')\n",
    "        ax2.legend()\n",
    "        # plt.savefig(f'Expected Loss Simulation {i}')\n",
    "        plt.show()\n",
    "\n",
    "def plot_simulations(file_name):\n",
    "    simulations = pd.read_csv(file_name)\n",
    "    no_of_simulations = simulations['simulation'].max()\n",
    "\n",
    "    _, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "    for i in range(1, no_of_simulations+1):\n",
    "\n",
    "        filtered = simulations[simulations['simulation'] == i]\n",
    "\n",
    "\n",
    "        if i == 1:\n",
    "            control = ax1.plot(filtered['sample'], filtered['control_expected_loss'], label='control')\n",
    "            treatment = ax1.plot(filtered['sample'], filtered['treatment_expected_loss'], label='treatment')\n",
    "            threshold = ax1.plot(filtered['sample'], np.full((10000,), 0.0015), label='threshold', linestyle='dashed')\n",
    "\n",
    "            ax2.plot(filtered['sample'], filtered['control_cr'], label='control', color=control[0].get_color())\n",
    "            ax2.plot(filtered['sample'], filtered['treatment_cr'], label='treatment', color=treatment[0].get_color())\n",
    "        else:\n",
    "            ax1.plot(filtered['sample'], filtered['control_expected_loss'], linewidth=0.25, color=control[0].get_color(), alpha=0.3)\n",
    "            ax1.plot(filtered['sample'], filtered['treatment_expected_loss'], linewidth=0.25, color=treatment[0].get_color(), alpha=0.3)\n",
    "            ax2.plot(filtered['sample'], filtered['control_cr'], linewidth=0.25, color=control[0].get_color(), alpha=0.3)\n",
    "            ax2.plot(filtered['sample'], filtered['treatment_cr'], linewidth=0.25, color=treatment[0].get_color(), alpha=0.3)\n",
    "        \n",
    "        \n",
    "        ax1.set_xlabel('Sample Size')\n",
    "        ax1.set_ylabel('Expected Loss')\n",
    "        ax1.set_title('Expected Loss Simulation')\n",
    "        ax1.legend()\n",
    "        \n",
    "        \n",
    "        ax2.set_xlabel('Sample Size')\n",
    "        ax2.set_ylabel('Conversion Rates')\n",
    "        ax2.set_title('Conversion Rates Simulation')\n",
    "        ax2.legend()\n",
    "    \n",
    "    ax1.plot(filtered['sample'], np.full((10000,), 0.0015), label='threshold', linestyle='dashed', color=threshold[0].get_color())\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    plot_peeking_example()\n",
    "\n",
    "    plot_simulations('experiment_simulations_37.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e05afcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import beta\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import decimal\n",
    "decimal.getcontext().prec = 4\n",
    "\n",
    "\n",
    "def calculate_expected_loss(control_simulation, treatment_simulation, treatment_won, min_difference_delta=0):\n",
    "    loss_control = [max((j - min_difference_delta) - i, 0) for i,j in zip(control_simulation, treatment_simulation)]\n",
    "    loss_treatment = [max(i - (j - min_difference_delta), 0) for i,j in zip(control_simulation, treatment_simulation)]\n",
    "\n",
    "    all_loss_control = [int(i)*j for i,j in zip(treatment_won, loss_control)]\n",
    "    all_loss_treatment = [(1 - int(i))*j for i,j in zip(treatment_won, loss_treatment)]\n",
    "\n",
    "    expected_loss_control = np.mean(all_loss_control)\n",
    "    expected_loss_treatment = np.mean(all_loss_treatment)\n",
    "    return expected_loss_control, expected_loss_treatment\n",
    "\n",
    "\n",
    "def run_multiple_experiment_simulations(n, prior_alpha, prior_beta, control_cr, treatment_cr, epsilon, variant_sample_size=10000, min_simulations_per_experiment=0):\n",
    "    output = pd.DataFrame()\n",
    "\n",
    "    for simulation in range(0,n):\n",
    "        records = []\n",
    "        control_simulations = np.random.binomial(n=1, p=control_cr, size=variant_sample_size)\n",
    "        treatment_simulations = np.random.binomial(n=1, p=treatment_cr, size=variant_sample_size)\n",
    "        \n",
    "        sample_size = 0\n",
    "        control_conversions = 0\n",
    "        treatment_conversions = 0\n",
    "\n",
    "        for i in range(variant_sample_size):\n",
    "            sample_size += 1\n",
    "            control_conversions += control_simulations[i]\n",
    "            treatment_conversions += treatment_simulations[i]\n",
    "\n",
    "            control_pdfs = np.random.beta(prior_alpha + control_conversions, prior_beta + sample_size - control_conversions, size=1000)\n",
    "            treatment_pdfs = np.random.beta(prior_alpha + treatment_conversions, prior_beta + sample_size - treatment_conversions, size=1000)\n",
    "            treatment_pdf_higher = [i <= j for i,j in zip(control_pdfs, treatment_pdfs)]\n",
    "\n",
    "            expected_loss_control, expected_loss_treatment = calculate_expected_loss(control_pdfs, treatment_pdfs, treatment_pdf_higher)\n",
    "\n",
    "            if (simulation >= min_simulations_per_experiment) and (expected_loss_treatment <= epsilon):\n",
    "                records.append({'simulation': simulation+1, 'sample': sample_size, 'treatment_cr': (treatment_conversions/sample_size), 'control_cr': (control_conversions/sample_size), 'treatment_expected_loss': expected_loss_treatment, 'control_expected_loss': expected_loss_control, 'winner': 'treatment'})\n",
    "            elif (simulation >= min_simulations_per_experiment) and expected_loss_control <= epsilon:\n",
    "                records.append({'simulation': simulation+1, 'sample': sample_size, 'treatment_cr': (treatment_conversions/sample_size), 'control_cr': (control_conversions/sample_size), 'treatment_expected_loss': expected_loss_treatment, 'control_expected_loss': expected_loss_control, 'winner': 'control'})\n",
    "            else:\n",
    "                records.append({'simulation': simulation+1, 'sample': sample_size, 'treatment_cr': (treatment_conversions/sample_size), 'control_cr': (control_conversions/sample_size), 'treatment_expected_loss': expected_loss_treatment, 'control_expected_loss': expected_loss_control, 'winner': 'inconclusive'})\n",
    "\n",
    "        simulation_results = pd.DataFrame.from_records(records)\n",
    "        output = pd.concat([output, simulation_results])    \n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    standard_simulations = run_multiple_experiment_simulations(100, 7, 15, 0.32, 0.32*(1.15), 0.0015)\n",
    "    standard_simulations.to_csv('experiment_simulations_37.csv', index=False)\n",
    "\n",
    "    low_mde_simulations = run_multiple_experiment_simulations(100, 7, 15, 0.32, 0.32*(1.05), 0.0015)\n",
    "    low_mde_simulations.to_csv('experiment_simulations_34.csv', index=False)\n",
    "\n",
    "    high_mde_simulations = run_multiple_experiment_simulations(100, 7, 15, 0.32, 0.32*(1.3), 0.0015)\n",
    "    high_mde_simulations.to_csv('experiment_simulations_41.csv', index=False)\n",
    "\n",
    "    low_eps_simulations = run_multiple_experiment_simulations(100, 7, 15, 0.32, 0.32*(1.15), 0.0005)\n",
    "    low_eps_simulations.to_csv('experiment_simulations_low_eps.csv', index=False)\n",
    "\n",
    "    high_eps_simulations = run_multiple_experiment_simulations(100, 7, 15, 0.32, 0.32*(1.15), 0.003)\n",
    "    high_eps_simulations.to_csv('experiment_simulations_high_eps.csv', index=False)\n",
    "\n",
    "    low_lambda_simulations = run_multiple_experiment_simulations(100, 2, 20, 0.05, 0.05*(1.15), 0.05*(0.005))\n",
    "    low_lambda_simulations.to_csv('experiment_simulations_low_lambda.csv', index=False)\n",
    "\n",
    "    high_lambda_simulations = run_multiple_experiment_simulations(100, 13, 9, 0.6, 0.6*(1.15), 0.6*(0.005))\n",
    "    high_lambda_simulations.to_csv('experiment_simulations_high_lambda.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7586fcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=[1,3,4,6]\n",
    "a=[(i+1) for i in b]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00244a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "b = np.array([2,3,4,5])\n",
    "c = zip(a,b)\n",
    "\n",
    "print(tuple(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4b9589",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (\"John\", \"Charles\", \"Mike\")\n",
    "b = (\"Jenny\", \"Christy\", \"Monica\")\n",
    "\n",
    "x = zip(a, b)\n",
    "\n",
    "#use the tuple() function to display a readable version of the result:\n",
    "\n",
    "print(tuple(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8b7889",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
